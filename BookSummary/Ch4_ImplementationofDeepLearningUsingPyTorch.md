# Ch4. 파이토치를 이용한 딥러닝 구현

## 4.1 신경망과 딥러닝의 역사

딥러닝 : 층 수가 깊은 신경망

### 첫 번째 신경망 연구 붐

매컬럭-피츠 모형 -> **퍼셉트론**

입력의 총합을 변환하는 함수 : **활성화함수** (activation function)

- 헤비사이드 함수를 이용 (양수 - 1, 음수 - 0)

- $$
  z=H(\Sigma_{i=1}^N w_ix_i+x_0)
  $$


**퍼셉트론 학습규칙** 

- 뉴런과 뉴런 사이의 결합 가중치와 편향을 원하는 입출력 관계에 맞춰 학습 시키는 것 

**한계** 

- 단일층으로 된 퍼셉트론만으로는 XOR과 같은 비선형 형태의 입출력 관계를 나타낼 수 없음을 증명

=> 층 수를 늘리면 XOR의 입출력 관계 학습 가능!

### 두 번째 신경망 연구 붐

오차 역전파 알고리즘

**활성화 함수**: 헤비사이드 함수 -> 로지스틱 함수(시그모이드 함수) 사용

- $$
  z=1/(1+exp(-u))
  $$


- 입력이 0 부근일 때 출력값이 매끄럽게 0에서 1로 변화
  - 미분이 가능해짐!

**한계**

- 층 수가 많은 신경망은 제안한 방법을 이용한 학습이 제대로 이루어지지 않았음
  - 기울기 소실(혹은 폭발) 문제 (vanishing gradient problem)

### 세 번째 신경망 연구 붐

딥러닝(딥 빌리프 넷) - 층 수가 많은 신경망의 학습을 가능케 하는 방법을 제안

- 오토 인코더 : "신경망을 층 단위로 쪼갠 다음 각 부분의 신경망이 입력된 신호를 출력으로 재현할 수 있게끔 결합 가중치를 학습해서 이를 초깃값으로 사용하는 방법"
- 

---

## 4.2 딥러닝의 계산 과정

일반적인 지도학습은 두 단계로 구성

1. 학습 단계
   1. 신경망에 데이터를 입력
   2. 출력이 훈련 데이터의 정답 출력과 가능한 한 같아지도록 신경망의 결합 가중치를 학습
2. 추론 단계
   1. 정답 출력을 알 수 없는 테스트 입력 데이터 사용
   2. 데이터를 신경망에 입력, 출력 계산

### 추론 단계

입력 값과 결합 가중치들을 이용하여 출력값 계산

### 학습 단계

실제 출력이 기대했던 출력과 가능한 한 비슷해지도록 **결합 가중치를 조정**!

-  오차함수(손실함수)를 결정해야함
  - 회귀 - 제곱오차함수(MSE)
  - 분류 - 교차 엔트로피 함수(cross entropy)
- 오차를 계산한 뒤에, 오차를 줄이기 위해서 결합 가중치 조절
  - 조정값 : "각 출력 뉴런의 오차를 역시 각각의 결합 가중치로 미분한 값"
    - 미분한 값의 의미 : "어떤 결합 가중치를 조금 강하게 했을 떄 출력층에 오차가 얼마나 커지는가"
    - 미분한 값을 구하는 방법 : 오차 역전파 알고리즘
  - 미분을 이용해 결합 가중치를 조정 - 경사 하강법
    - Adam, RMSprop 등이 있다

**배치 학습**

- 여러 개 있는 입력 데이터를 모두 사용해서 결합 가중치를 조정하는 방법

**온라인 학습**

- 입력 데이터를 하나씩 사용해서 결합 가중치를 조정하는 방법

**미니배치 학습**

- 데이터를 여러 개 사용하지만 전체 데이터를 사용하지는 않고 결합 가중치를 조정하는 방법



학습 단계 요약

1. 추론 단계와 마찬가지로 입력값으로 출력을 계산
2. 기대하는 출력과 실제 출력 사이의 오차를 오차함수로 계산
3. 오차에 대한 각 결합 가중치ㅏ의 미분값을 오차 역전파 알고리즘으로 계산
4. 각 결합 가중치의 미분 값에 따라 경사 하강법으로 결합 가중치를 수정
5. 1로 돌아간다.

---

## 4.3 파이토치를 이용한 MNIST 손글씨 이미지 분류 구현

### 파이토치란?

카페, 텐서플로, 케라스, 체이너 등과 같은 **딥러닝용 패키지**

**장점**

- 설계상으로 Define by Run(동적 계산 그래프)이라는 사상을 따름
  - 입력 데이터의 크기나 차원 수에 맞춰 신경망의 구조와 계산 과정을 변화시킬 수 있다.



### 파이토치 개발환경 갖추기

http://pytorch.org 참고

- 운영체제 종류, PC 버전, 그래픽카드 유무에 따라 코드가 달라짐

### MNIST 데이터 다운로드

사이킷 런 라이브러리 설치

- conda install scikit-learn

### 파이토치를 이용한 딥러닝 구현



#### 데이터 전처리

데이터를 신경망에 입력할 수 있도록 가공

#### DataLoader 생성

파이토치 신경망에서 다룰 수 있게 DataLoader 객체로 변환

- 훈련 데이터와 테스트 데이터로 분할
- NumPy 배열을 Tensor 객체로 변환
  - 텐서 : 숫자를 여러 차원으로 늘어놓은 것
    - 스칼라 - 숫자값이 하나
    - 벡터 - 1차원으로 열거
    - 행렬 - 2차원으로 결거
- Dataset 객체 생성
- Dataset 객체를 DataLoader 객체로 변환
  - 배치 크기 - 신경망의 결합 가중치를 한 번 수정할 때 사용되는 데이터의 건수

#### 신경망 구성

fc1 -> relu1 -> fc2 -> relu2 -> fc3

#### 오차함수 및 최적화 기법 설정

분류 문제 - 교차 엔트로피 함수

경사 하강법 알고리즘 - Adam

#### 학습 및 추론 설정

#### 학습 및 추론 수행



### 파이토치 사용법에 대한 보충 설명

