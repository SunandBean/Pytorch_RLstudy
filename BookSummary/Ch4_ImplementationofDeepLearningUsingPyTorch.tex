\PassOptionsToPackage{unicode=true}{hyperref} % options for packages loaded elsewhere
\PassOptionsToPackage{hyphens}{url}
%
\documentclass[]{article}
\usepackage{lmodern}
\usepackage{amssymb,amsmath}
\usepackage{ifxetex,ifluatex}
\usepackage{fixltx2e} % provides \textsubscript
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provides euro and other symbols
\else % if luatex or xelatex
  \usepackage{unicode-math}
  \defaultfontfeatures{Ligatures=TeX,Scale=MatchLowercase}
\fi
% use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
% use microtype if available
\IfFileExists{microtype.sty}{%
\usepackage[]{microtype}
\UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\IfFileExists{parskip.sty}{%
\usepackage{parskip}
}{% else
\setlength{\parindent}{0pt}
\setlength{\parskip}{6pt plus 2pt minus 1pt}
}
\usepackage{hyperref}
\hypersetup{
            pdfborder={0 0 0},
            breaklinks=true}
\urlstyle{same}  % don't use monospace font for urls
\setlength{\emergencystretch}{3em}  % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{0}
% Redefines (sub)paragraphs to behave more like sections
\ifx\paragraph\undefined\else
\let\oldparagraph\paragraph
\renewcommand{\paragraph}[1]{\oldparagraph{#1}\mbox{}}
\fi
\ifx\subparagraph\undefined\else
\let\oldsubparagraph\subparagraph
\renewcommand{\subparagraph}[1]{\oldsubparagraph{#1}\mbox{}}
\fi

% set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother


\date{}

\begin{document}

\hypertarget{header-n0}{%
\section{Ch4. 파이토치를 이용한 딥러닝 구현}\label{header-n0}}

\hypertarget{header-n2}{%
\subsection{4.1 신경망과 딥러닝의 역사}\label{header-n2}}

딥러닝 : 층 수가 깊은 신경망

\hypertarget{header-n4}{%
\subsubsection{첫 번째 신경망 연구 붐}\label{header-n4}}

매컬럭-피츠 모형 -\textgreater{} \textbf{퍼셉트론}

입력의 총합을 변환하는 함수 : \textbf{활성화함수} (activation function)

\begin{itemize}
\item
  헤비사이드 함수를 이용 (양수 - 1, 음수 - 0)
\item
  \[z=H(\Sigma_{i=1}^N w_ix_i+x_0)\]
\end{itemize}

\textbf{퍼셉트론 학습규칙}

\begin{itemize}
\item
  뉴런과 뉴런 사이의 결합 가중치와 편향을 원하는 입출력 관계에 맞춰 학습
  시키는 것 
\end{itemize}

\textbf{한계}

\begin{itemize}
\item
  단일층으로 된 퍼셉트론만으로는 XOR과 같은 비선형 형태의 입출력 관계를
  나타낼 수 없음을 증명
\end{itemize}

=\textgreater{} 층 수를 늘리면 XOR의 입출력 관계 학습 가능!

\hypertarget{header-n21}{%
\subsubsection{두 번째 신경망 연구 붐}\label{header-n21}}

오차 역전파 알고리즘

\textbf{활성화 함수}: 헤비사이드 함수 -\textgreater{} 로지스틱
함수(시그모이드 함수) 사용

\begin{itemize}
\tightlist
\item
  \[z=1/(1+exp(-u))\]
\end{itemize}

\begin{itemize}
\item
  입력이 0 부근일 때 출력값이 매끄럽게 0에서 1로 변화

  \begin{itemize}
  \item
    미분이 가능해짐!
  \end{itemize}
\end{itemize}

\textbf{한계}

\begin{itemize}
\item
  층 수가 많은 신경망은 제안한 방법을 이용한 학습이 제대로 이루어지지
  않았음

  \begin{itemize}
  \item
    기울기 소실(혹은 폭발) 문제 (vanishing gradient problem)
  \end{itemize}
\end{itemize}

\hypertarget{header-n41}{%
\subsubsection{세 번째 신경망 연구 붐}\label{header-n41}}

딥러닝(딥 빌리프 넷) - 층 수가 많은 신경망의 학습을 가능케 하는 방법을
제안

\begin{itemize}
\item
  오토 인코더 : "신경망을 층 단위로 쪼갠 다음 각 부분의 신경망이 입력된
  신호를 출력으로 재현할 수 있게끔 결합 가중치를 학습해서 이를
  초깃값으로 사용하는 방법"
\item
\end{itemize}

\begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

\hypertarget{header-n49}{%
\subsection{4.2 딥러닝의 계산 과정}\label{header-n49}}

일반적인 지도학습은 두 단계로 구성

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  학습 단계

  \begin{enumerate}
  \def\labelenumii{\arabic{enumii}.}
  \item
    신경망에 데이터를 입력
  \item
    출력이 훈련 데이터의 정답 출력과 가능한 한 같아지도록 신경망의 결합
    가중치를 학습
  \end{enumerate}
\item
  추론 단계

  \begin{enumerate}
  \def\labelenumii{\arabic{enumii}.}
  \item
    정답 출력을 알 수 없는 테스트 입력 데이터 사용
  \item
    데이터를 신경망에 입력, 출력 계산
  \end{enumerate}
\end{enumerate}

\hypertarget{header-n66}{%
\subsubsection{추론 단계}\label{header-n66}}

입력 값과 결합 가중치들을 이용하여 출력값 계산

\hypertarget{header-n68}{%
\subsubsection{학습 단계}\label{header-n68}}

실제 출력이 기대했던 출력과 가능한 한 비슷해지도록 \textbf{결합 가중치를
조정}!

\begin{itemize}
\item
  오차함수(손실함수)를 결정해야함
\item
  회귀 - 제곱오차함수(MSE)
\item
  분류 - 교차 엔트로피 함수(cross entropy)
\item
  오차를 계산한 뒤에, 오차를 줄이기 위해서 결합 가중치 조절

  \begin{itemize}
  \item
    조정값 : "각 출력 뉴런의 오차를 역시 각각의 결합 가중치로 미분한 값"

    \begin{itemize}
    \item
      미분한 값의 의미 : "어떤 결합 가중치를 조금 강하게 했을 떄
      출력층에 오차가 얼마나 커지는가"
    \item
      미분한 값을 구하는 방법 : 오차 역전파 알고리즘
    \end{itemize}
  \item
    미분을 이용해 결합 가중치를 조정 - 경사 하강법

    \begin{itemize}
    \item
      Adam, RMSprop 등이 있다
    \end{itemize}
  \end{itemize}
\end{itemize}

\textbf{배치 학습}

\begin{itemize}
\item
  여러 개 있는 입력 데이터를 모두 사용해서 결합 가중치를 조정하는 방법
\end{itemize}

\textbf{온라인 학습}

\begin{itemize}
\item
  입력 데이터를 하나씩 사용해서 결합 가중치를 조정하는 방법
\end{itemize}

\textbf{미니배치 학습}

\begin{itemize}
\item
  데이터를 여러 개 사용하지만 전체 데이터를 사용하지는 않고 결합
  가중치를 조정하는 방법
\end{itemize}

학습 단계 요약

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  추론 단계와 마찬가지로 입력값으로 출력을 계산
\item
  기대하는 출력과 실제 출력 사이의 오차를 오차함수로 계산
\item
  오차에 대한 각 결합 가중치ㅏ의 미분값을 오차 역전파 알고리즘으로 계산
\item
  각 결합 가중치의 미분 값에 따라 경사 하강법으로 결합 가중치를 수정
\item
  1로 돌아간다.
\end{enumerate}

\begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

\hypertarget{header-n118}{%
\subsection{4.3 파이토치를 이용한 MNIST 손글씨 이미지 분류
구현}\label{header-n118}}

\hypertarget{header-n119}{%
\subsubsection{파이토치란?}\label{header-n119}}

카페, 텐서플로, 케라스, 체이너 등과 같은 \textbf{딥러닝용 패키지}

\textbf{장점}

\begin{itemize}
\item
  설계상으로 Define by Run(동적 계산 그래프)이라는 사상을 따름

  \begin{itemize}
  \item
    입력 데이터의 크기나 차원 수에 맞춰 신경망의 구조와 계산 과정을
    변화시킬 수 있다.
  \end{itemize}
\end{itemize}

\hypertarget{header-n129}{%
\subsubsection{파이토치 개발환경 갖추기}\label{header-n129}}

http://pytorch.org 참고

\begin{itemize}
\item
  운영체제 종류, PC 버전, 그래픽카드 유무에 따라 코드가 달라짐
\end{itemize}

\hypertarget{header-n134}{%
\subsubsection{MNIST 데이터 다운로드}\label{header-n134}}

사이킷 런 라이브러리 설치

\begin{itemize}
\item
  conda install scikit-learn
\end{itemize}

\hypertarget{header-n139}{%
\subsubsection{파이토치를 이용한 딥러닝 구현}\label{header-n139}}

\hypertarget{header-n141}{%
\paragraph{데이터 전처리}\label{header-n141}}

데이터를 신경망에 입력할 수 있도록 가공

\hypertarget{header-n143}{%
\paragraph{DataLoader 생성}\label{header-n143}}

파이토치 신경망에서 다룰 수 있게 DataLoader 객체로 변환

\begin{itemize}
\item
  훈련 데이터와 테스트 데이터로 분할
\item
  NumPy 배열을 Tensor 객체로 변환

  \begin{itemize}
  \item
    텐서 : 숫자를 여러 차원으로 늘어놓은 것

    \begin{itemize}
    \item
      스칼라 - 숫자값이 하나
    \item
      벡터 - 1차원으로 열거
    \item
      행렬 - 2차원으로 결거
    \end{itemize}
  \end{itemize}
\item
  Dataset 객체 생성
\item
  Dataset 객체를 DataLoader 객체로 변환

  \begin{itemize}
  \item
    배치 크기 - 신경망의 결합 가중치를 한 번 수정할 때 사용되는 데이터의
    건수
  \end{itemize}
\end{itemize}

\hypertarget{header-n167}{%
\paragraph{신경망 구성}\label{header-n167}}

fc1 -\textgreater{} relu1 -\textgreater{} fc2 -\textgreater{} relu2
-\textgreater{} fc3

\hypertarget{header-n169}{%
\paragraph{오차함수 및 최적화 기법 설정}\label{header-n169}}

분류 문제 - 교차 엔트로피 함수

경사 하강법 알고리즘 - Adam

\hypertarget{header-n172}{%
\paragraph{학습 및 추론 설정}\label{header-n172}}

\hypertarget{header-n173}{%
\paragraph{학습 및 추론 수행}\label{header-n173}}

\hypertarget{header-n175}{%
\subsubsection{파이토치 사용법에 대한 보충 설명}\label{header-n175}}

\end{document}
